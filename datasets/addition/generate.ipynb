{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca7d9dc9-10c9-4c44-b574-6051e677184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a31db260-4c6e-4509-9f13-dbca269a9f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Max Number: 5\n",
      "Train-Test-Split: 0.5\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "defaults = {\n",
    "    \"max_number\": 5,\n",
    "    \"train_test_split\": 0.5\n",
    "}\n",
    "\n",
    "config = get_arguments(defaults)\n",
    "\n",
    "print(\"=\" * 40)\n",
    "print(f\"Max Number: {config[\"max_number\"]}\")\n",
    "print(f\"Train-Test-Split: {config[\"train_test_split\"]}\")\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e679bbcd-0d07-4ffc-84f7-63fb1c11e363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In our Vocabulary we need a Token for each number + a equal symbol, thus bringing the total Vocabulary Size to 7 when having Numbers 0 to 5 and an Equal Symbole.\n",
      "\n",
      "Those are the two values we want to add together:\n",
      "tensor([[0, 0],\n",
      "        [0, 1],\n",
      "        [0, 2],\n",
      "        [0, 3],\n",
      "        [0, 4],\n",
      "        [0, 5],\n",
      "        [1, 0],\n",
      "        [1, 1],\n",
      "        [1, 2],\n",
      "        [1, 3],\n",
      "        [1, 4],\n",
      "        [1, 5],\n",
      "        [2, 0],\n",
      "        [2, 1],\n",
      "        [2, 2],\n",
      "        [2, 3],\n",
      "        [2, 4],\n",
      "        [2, 5],\n",
      "        [3, 0],\n",
      "        [3, 1],\n",
      "        [3, 2],\n",
      "        [3, 3],\n",
      "        [3, 4],\n",
      "        [3, 5],\n",
      "        [4, 0],\n",
      "        [4, 1],\n",
      "        [4, 2],\n",
      "        [4, 3],\n",
      "        [4, 4],\n",
      "        [4, 5],\n",
      "        [5, 0],\n",
      "        [5, 1],\n",
      "        [5, 2],\n",
      "        [5, 3],\n",
      "        [5, 4],\n",
      "        [5, 5]])\n",
      "\n",
      "We generate a Dataset that consists of Tokens: [ Num A Token, Num B Token, Equal Token, Num Sum Token (A + B mod Max Number) ]. Our first 3 Elements in the shuffled dataset look as follows:\n",
      "1. [1, 0, 6, 1]\n",
      "2. [0, 3, 6, 3]\n",
      "3. [5, 0, 6, 5]\n",
      "\n",
      "When replaceing Token IDs with Token Strings in our Dataset look as follows:\n",
      "1. ['1', '0', '=', '1']\n",
      "2. ['0', '3', '=', '3']\n",
      "3. ['5', '0', '=', '5']\n",
      "\n",
      "Our Dataset elements formatted look like this:\n",
      "1. 1 + 0 = 1\n",
      "2. 0 + 3 = 3\n",
      "3. 5 + 0 = 5\n",
      "\n",
      "After splitting our Dataset to a train and a test split in a ratio 50%, we receive 18 items in our train split and 18 items in our test set.\n"
     ]
    }
   ],
   "source": [
    "vocab = generate_vocabulary(config[\"max_number\"])\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(f\"In our Vocabulary we need a Token for each number + a equal symbol, thus bringing the total Vocabulary Size to {vocab_size} when having Numbers 0 to {config[\"max_number\"]} and an Equal Symbole.\")\n",
    "print()\n",
    "\n",
    "number_subsets = generate_subsets_set_of_two_numbers(config[\"max_number\"])\n",
    "\n",
    "print(\"Those are the two values we want to add together:\")\n",
    "print(torch.tensor(number_subsets, dtype=torch.long))\n",
    "print()\n",
    "\n",
    "dataset = generate_dataset_from_number_subsets(number_subsets, vocab_size)\n",
    "\n",
    "indexes = torch.randperm(dataset.shape[0])\n",
    "dataset = dataset[indexes]\n",
    "\n",
    "print(\"We generate a Dataset that consists of Tokens: [ Num A Token, Num B Token, Equal Token, Num Sum Token (A + B mod Max Number) ]. Our first 3 Elements in the shuffled dataset look as follows:\")\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"{i + 1}. {dataset[i].tolist()}\")\n",
    "\n",
    "print()\n",
    "print(\"When replaceing Token IDs with Token Strings in our Dataset look as follows:\")\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"{i + 1}. {[ vocab[token_id] for token_id in dataset[i].tolist() ]}\")\n",
    "\n",
    "print()\n",
    "print(\"Our Dataset elements formatted look like this:\")\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"{i + 1}. {format_addition_to_string(dataset[i].tolist(), vocab)}\")\n",
    "\n",
    "print()\n",
    "\n",
    "dataset_train_split, dataset_test_split = generate_dataset_splits(dataset, config[\"train_test_split\"])\n",
    "\n",
    "print(f\"After splitting our Dataset to a train and a test split in a ratio {int(config[\"train_test_split\"] * 100)}%, we receive {dataset_train_split.shape[0]} items in our train split and {dataset_test_split.shape[0]} items in our test set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76152444-d81f-4af1-b29a-31442aaab1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataset_train_split, \"dataset_train.pt\")\n",
    "torch.save(dataset_test_split, \"dataset_test.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
